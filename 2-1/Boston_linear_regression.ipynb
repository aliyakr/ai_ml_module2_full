{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модуль 2. Занятие 1. Сравнение линейных моделей и градиентного спуска в машинном обучении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных California Housing включает информацию о жилищных условиях в Калифорнии, собранную на основе переписи США 1990 года. Каждый ряд представляет данные для одного района и включает различные признаки, которые могут помочь предсказать стоимость жилья. Вот описание столбцов:\n",
    "\n",
    "- MedInc: Средний доход домохозяйства в районе (в десятках тысяч долларов).\n",
    "- HouseAge: Средний возраст домов в районе.\n",
    "- AveRooms: Среднее количество комнат на домохозяйство.\n",
    "- AveBedrms: Среднее количество спален на домохозяйство.\n",
    "- Population: Численность населения в районе.\n",
    "- AveOccup: Среднее количество жильцов на дом.\n",
    "- Latitude: Широта района.\n",
    "- Longitude: Долгота района.\n",
    "- MedHouseVal (целевая переменная): Средняя стоимость жилья в районе (в сотнях тысяч долларов).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель работы с этим набором данных заключается в предсказании средней стоимости жилья (MedHouseVal) на основе других признаков, чтобы выявить факторы, влияющие на цены недвижимости в Калифорнии.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных разбит на два для этого анализа: один для обучения (70% образцов) и один для тестирования (30% образцов). После разработки модели на основе данных обучения ее производительность будет проверяться на данных тестирования. Три модели будут сравниваться после их установки:\n",
    "1. a linear model using all variables\n",
    "2. a linear model after variable selection\n",
    "3. a Gradient Boosting Machine (GBM) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем данные из библиотеки sklearn (встроенный датасет). Параметр as_frame при импорте позволяет нам взглянуть на данные в привычном нам формате датафрейма. Сразу разделим данные на признаки и таргет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IagME5lVQfTi",
    "outputId": "7eaf26e7-fd80-4d36-f214-1043b7a6f982"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing.frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деление данных на тренировочные и тестовые наборы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного теории:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деление данных на тренировочный и тестовый наборы — это один из ключевых шагов в процессе обучения моделей машинного обучения. Цель такого деления — обеспечить, чтобы модель могла быть проверена на данных, которые она не видела во время обучения, для оценки её обобщающей способности. Основные способы деления данных:\n",
    "\n",
    "1. Простое деление (Holdout) <br>\n",
    "\n",
    "Самый простой способ — случайное деление данных на две части: тренировочную и тестовую. Обычно берут 70–80% данных для тренировки и 20–30% для тестирования. Этот способ прост и подходит для больших датасетов, но его недостаток в том, что оценка модели может быть нестабильной, если выборка небольшая или случайное деление сильно повлияло на данные.<br>\n",
    "\n",
    "2. Кросс-валидация (Cross-Validation)<br>\n",
    "\n",
    "Кросс-валидация улучшает оценку, разбивая данные на k частей (фолдов), и каждый фолд по очереди используется как тестовый, а остальные k−1 — как тренировочные. Наиболее распространённый вариант — это 5-кратная (k=5) или 10-кратная (k=10) кросс-валидация. Средний результат по всем фолдам считается общей оценкой модели. Это позволяет уменьшить зависимость от случайного деления и даёт более стабильные результаты.<br>\n",
    "\n",
    "3. Стратифицированное деление (Stratified Split)<br>\n",
    "\n",
    "Стратифицированное деление учитывает распределение классов в данных. Это важно в задачах классификации, где может быть перекос классов. При стратифицированной кросс-валидации или стратифицированном простом делении каждый фолд или набор данных содержит пропорциональное количество экземпляров каждого класса. Это уменьшает вероятность получения смещённых оценок.<br>\n",
    "\n",
    "4. Временное деление (Time Series Split)<br>\n",
    "\n",
    "Для временных рядов и последовательных данных используется временное деление. В таких данных нельзя делать случайное деление, поскольку это нарушает временную структуру. В этом методе данные делятся на основе времени, например, первые 80% данных используются для тренировки, а последние 20% — для теста. Также существует кросс-валидация для временных рядов, при которой каждый раз данные делятся на основе временных последовательностей (например, rolling windows).<br>\n",
    "\n",
    "5. Leave-One-Out Cross-Validation (LOO CV)<br>\n",
    "\n",
    "Это особый случай кросс-валидации, когда каждый экземпляр данных по очереди используется как тестовый набор, а остальные — как тренировочный. Этот метод используется для небольших датасетов, так как он очень затратный по времени, но может дать точные оценки для маленьких наборов данных.<br>\n",
    "\n",
    "6. Shuffle Split<br>\n",
    "\n",
    "В Shuffle Split данные многократно перемешиваются и делятся на тренировочную и тестовую выборки, подобно кросс-валидации, но без деления на фолды. Он используется, когда требуется несколько случайных разбиений без сложной структуры кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>В Python для разделения данных на тренировочный и тестовый наборы используются популярные методы из библиотек scikit-learn и pandas.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`train_test_split`**— основной и простой в использовании метод для случайного деления данных. Он позволяет указать долю данных, которая пойдёт в тестовый набор, и опцию стратификации для сохранения пропорций классов в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь test_size задает долю для тестирования (аналогично можно задать train_size), a random_state=42 фиксирует случайное разделение для воспроизводимости (т.е. разделение будет фиксированным при каждом запуске кода). Число 42 стало популярным благодаря книге Дугласа Адамса «Автостопом по галактике», где оно фигурирует как «ответ на главный вопрос жизни, Вселенной и всего такого». В итоге, random_state=42 стало полушуточным стандартом среди программистов, хотя любое другое число могло бы подойти для этой цели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Делим данные на 80% тренировочных и 20% тестовых\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`KFold`** реализует классический метод кросс-валидации. Он разбивает данные на k фолдов (частей), и каждый фолд поочередно используется как тестовый набор, а остальные k-1 фолдов — как тренировочный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_splits: Количество фолдов. Обычно используются значения 5 или 10.\n",
    "- shuffle: Опция перемешивания данных перед разбиением, что полезно для случайных выборок из упорядоченных данных.\n",
    "- random_state: Обеспечивает воспроизводимость при включённом перемешивании"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Когда использовать:</b>\n",
    "Подходит для задач с большим количеством данных, когда важно оценить модель на разных разбиениях. Обеспечивает надёжную оценку и помогает избежать переобучения на тренировочном наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`StratifiedKFold`** — это версия KFold, которая сохраняет пропорции классов в каждом фолде. Полезен для задач классификации с несбалансированными классами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Когда использовать:</b>\n",
    "Эффективен для задач классификации с несбалансированными данными, так как обеспечивает равномерное распределение классов в каждом фолде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`TimeSeriesSplit`** подходит для данных временных рядов, где последовательность важна. Вместо случайного разбиения каждый новый фолд использует предыдущие данные, что соответствует реальной последовательности событий во времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ShuffleSplit`** создаёт несколько случайных разбиений, где данные каждый раз случайно перемешиваются и делятся на тренировочную и тестовую выборки. В отличие от KFold, тут нет строго структурированных фолдов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Когда использовать:</b>\n",
    "Подходит для задач, где нужно несколько случайных разбиений для более надёжной оценки модели, но где не требуется полноценная кросс-валидация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in ss.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наши данные на тренировочный и тестовый датасеты в соотношении 70 на 30. Для этого используется встроенная в sklearn функция train_test_split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6xtL4lPQrBL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset: 70% vs 30% \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 2. Выбор и обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая модель, которую мы будем сравнивать - модель простой линейной регрессии. Для ее оценки воспользуемся статистической метрикой R^2 Score и прогоним модель на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QgobxBSRq9w"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybrbAnR7SOzb",
    "outputId": "d66601ec-dd1b-4acf-9944-ce7cf8a4ae3a"
   },
   "outputs": [],
   "source": [
    "# initiate the linear model and fit with data\n",
    "lm =LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`R² (коэффициент детерминации)`** — это метрика, которая используется для оценки качества модели регрессии. Она показывает, насколько хорошо модель объясняет вариацию целевой переменной. Значение R² варьируется от 0 до 1 (или может быть отрицательным в случае плохой модели)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Интерпретация R²</b>\n",
    "- R² = 1 означает, что модель идеально предсказывает целевую переменную: вся вариация в данных объясняется моделью.\n",
    "- R² = 0 означает, что модель не объясняет вариацию целевой переменной лучше, чем среднее значение целевой переменной.\n",
    "- R² < 0 может возникнуть, если модель предсказывает хуже, чем простая модель, предсказывающая среднее значение для всех примеров.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем ближе значение R² к 1, тем лучше модель справляется с предсказанием целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAVFAZzzT2mk",
    "outputId": "8ddfbab3-02c1-49e2-dc71-bfefac484434"
   },
   "outputs": [],
   "source": [
    "print(\"The R-squared value is: {0:0.4f} \\n\".format(lm.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Интерсепт`** (перехват, intercept) в модели линейной регрессии — это значение, которое модель предскажет для целевой переменной y, когда все признаки X равны нулю. Интерсепт — это константа, которая добавляется к линейной комбинации признаков, чтобы сместить линию регрессии вверх или вниз по оси y. Это позволяет модели лучше подстроиться под данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = housing.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYe_59pwUgTN",
    "outputId": "0843dfaa-95e4-4a3a-dae5-30cc0311aa71"
   },
   "outputs": [],
   "source": [
    "param_df = pd.DataFrame({\"Features\": ['intercept'] + list(feature_names), \n",
    "\"Coef\": [lm.intercept_] + list(lm.coef_)}) \n",
    "cols = param_df.columns.tolist() \n",
    "cols = cols[-1:]+cols[:-1] \n",
    "param_df = param_df[cols] \n",
    "print(param_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим работу модели на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnlXvvm9Vr9F"
   },
   "outputs": [],
   "source": [
    "#%% check performance on test data \n",
    "predicted = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FHPdN3KWCFZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mae = np.mean(abs(predicted-y_test))\n",
    "rmse = np.sqrt(np.mean((predicted-y_test)**2))\n",
    "rae = np.mean(abs(predicted-y_test))/np.mean(abs(y_test-np.mean(y_test)))\n",
    "rse = np.mean((predicted-y_test)**2)/np.mean((y_test-np.mean(y_test))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`MAE`** (средняя абсолютная ошибка) рассчитывает среднее значение абсолютных ошибок между предсказанными и фактическими значениями. Она измеряет среднее отклонение предсказаний от истинных значений без учета знака ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Интерпретация:</b>\n",
    "\n",
    "- Чем меньше значение MAE, тем точнее предсказания модели.\n",
    "- MAE интуитивно понятна, так как показывает среднюю величину ошибки в тех же единицах измерения, что и целевая переменная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEutwNTWWLbT",
    "outputId": "06b2a3a3-59ea-455c-9070-fc445012f3a7"
   },
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`RMSE`** (Корень средней квадратичной ошибки) также измеряет среднее отклонение предсказанных значений от фактических, но в отличие от MAE, она более чувствительна к большим ошибкам, так как возводит каждую ошибку в квадрат перед усреднением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Интерпретация:</b>\n",
    "\n",
    "- Чем меньше RMSE, тем точнее предсказания модели.\n",
    "- Так как RMSE возводит ошибки в квадрат, она более чувствительна к выбросам, чем MAE. Большие ошибки дают непропорционально больший вклад в метрику, поэтому RMSE часто используется, когда важны не только средние ошибки, но и их распределение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIP1nsQnW0ZP",
    "outputId": "bd774bfc-8deb-4d79-81a3-b29d20c5edd1"
   },
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`RAE`** (относительная абсолютная ошибка) измеряет суммарную абсолютную ошибку модели по отношению к суммарной абсолютной ошибке базовой модели, которая всегда предсказывает среднее значение целевой переменной. По сути, это нормализованная версия MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Интерпретация:</b>\n",
    "\n",
    "- RAE показывает, насколько модель лучше (или хуже) простой модели, предсказывающей среднее значение. Если RAE < 1, значит модель лучше, чем среднее предсказание.\n",
    "- Она полезна для сравнения моделей, так как учитывает масштаб и вариативность целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HoD0CpyW4mB",
    "outputId": "94fefbbf-07bc-4d5e-e14e-6a0d1408a7c7"
   },
   "outputs": [],
   "source": [
    "rae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`RSE`** измеряет суммарную квадратичную ошибку модели по отношению к суммарной квадратичной ошибке базовой модели (которая предсказывает среднее значение целевой переменной). Это нормализованная версия RMSE, аналог R² в обратном смысле (чем меньше, тем лучше)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Интерпретация:</b>\n",
    "\n",
    "- Значение RSE < 1 указывает на то, что модель лучше, чем простое среднее предсказание; RSE > 1 — что хуже.\n",
    "- Чем меньше значение RSE, тем лучше модель объясняет вариацию данных по сравнению с базовой моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3badiP8W5_I",
    "outputId": "6d619efb-6289-4264-d27f-0306e3c8f546"
   },
   "outputs": [],
   "source": [
    "rse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u3u25lDoW7c5",
    "outputId": "2dee88cd-b5c0-4aac-b21d-b112e783045d"
   },
   "outputs": [],
   "source": [
    "print(\"The R-squared value is: {0:0.4f}\".format(lm.score(X_test, y_test))) \n",
    "print(\"Mean Absolute Error: {0:0.6f}\".format(mae)) \n",
    "print(\"Root Mean Squared Error: {0:0.6f}\".format(rmse)) \n",
    "print(\"Relative Absolute Error: {0:0.6f}\".format(rae)) \n",
    "print(\"Relative Squared Error: {0:0.6f}\".format(rse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAvxTISfYUxX",
    "outputId": "70a8bcf6-be37-4b05-b42e-aae730cea024"
   },
   "outputs": [],
   "source": [
    "# print metrics on test data\n",
    "print(\"The R-squared value is: {0:0.4f} \\n\".format(lm2.score(X_train_new, y_train)))\n",
    "print(\"Mean Absolute Error: {0:0.6f}\".format(mae))\n",
    "print(\"Root Mean Squared Error: {0:0.6f}\".format(rmse))\n",
    "print(\"Relative Absolute Error: {0:0.6f}\".format(rae))\n",
    "print(\"Relative Squared Error: {0:0.6f}\".format(rse))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdnS_gYT3xb-",
    "outputId": "0a5ee60e-715d-4d80-c968-41a7fbc2708f"
   },
   "outputs": [],
   "source": [
    "print(\"The R-squared value is: {0:0.4f}\".format(Ridge.score(X_test, y_test))) \n",
    "print(\"Mean Absolute Error: {0:0.6f}\".format(mae)) \n",
    "print(\"Root Mean Squared Error: {0:0.6f}\".format(rmse)) \n",
    "print(\"Relative Absolute Error: {0:0.6f}\".format(rae)) \n",
    "print(\"Relative Squared Error: {0:0.6f}\".format(rse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dha5a9IcWVuL",
    "outputId": "6673e90d-a31f-4c5a-d90b-c83bf0502401"
   },
   "outputs": [],
   "source": [
    "predicted_Lasso = Lasso.predict(X_test)\n",
    "mae = np.mean(abs(predicted_Lasso-y_test))\n",
    "rmse = np.sqrt(np.mean((predicted_Lasso-y_test)**2))\n",
    "rae = np.mean(abs(predicted_Lasso-y_test))/np.mean(abs(y_test-np.mean(y_test)))\n",
    "rse = np.mean((predicted_Lasso-y_test)**2)/np.mean((y_test-np.mean(y_test))**2)\n",
    "print(\"The R-squared value is: {0:0.4f}\".format(Lasso.score(X_test, y_test))) \n",
    "print(\"Mean Absolute Error: {0:0.6f}\".format(mae)) \n",
    "print(\"Root Mean Squared Error: {0:0.6f}\".format(rmse)) \n",
    "print(\"Relative Absolute Error: {0:0.6f}\".format(rae)) \n",
    "print(\"Relative Squared Error: {0:0.6f}\".format(rse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJ0deR1qX--X",
    "outputId": "f79bafa7-9e65-46c1-b923-2cfe9c345c33"
   },
   "outputs": [],
   "source": [
    "predicted_ElasticNetCV = ElasticNetCV.predict(X_test)\n",
    "mae = np.mean(abs(predicted_ElasticNetCV-y_test))\n",
    "rmse = np.sqrt(np.mean((predicted_Lasso-y_test)**2))\n",
    "rae = np.mean(abs(predicted_ElasticNetCV-y_test))/np.mean(abs(y_test-np.mean(y_test)))\n",
    "rse = np.mean((predicted_ElasticNetCV-y_test)**2)/np.mean((y_test-np.mean(y_test))**2)\n",
    "print(\"The R-squared value is: {0:0.4f}\".format(ElasticNetCV.score(X_test, y_test))) \n",
    "print(\"Mean Absolute Error: {0:0.6f}\".format(mae)) \n",
    "print(\"Root Mean Squared Error: {0:0.6f}\".format(rmse)) \n",
    "print(\"Relative Absolute Error: {0:0.6f}\".format(rae)) \n",
    "print(\"Relative Squared Error: {0:0.6f}\".format(rse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mjF6lZBeuqY",
    "outputId": "b40cc255-2e8b-429e-9d55-ef1256e5718e"
   },
   "outputs": [],
   "source": [
    "predicted_SGD = SGD.predict(X_test)\n",
    "mae = np.mean(abs(predicted_SGD-y_test))\n",
    "rmse = np.sqrt(np.mean((predicted_SGD-y_test)**2))\n",
    "rae = np.mean(abs(predicted_SGD-y_test))/np.mean(abs(y_test-np.mean(y_test)))\n",
    "rse = np.mean((predicted_SGD-y_test)**2)/np.mean((y_test-np.mean(y_test))**2)\n",
    "print(\"The R-squared value is: {0:0.4f}\".format(SGD.score(X_test, y_test))) \n",
    "print(\"Mean Absolute Error: {0:0.6f}\".format(mae)) \n",
    "print(\"Root Mean Squared Error: {0:0.6f}\".format(rmse)) \n",
    "print(\"Relative Absolute Error: {0:0.6f}\".format(rae)) \n",
    "print(\"Relative Squared Error: {0:0.6f}\".format(rse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализуем данные и применим RFE (метод рекурсивного исключения признаков) и RFECV (метод рекурсивного исключения признаков с кросс-валидацией)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wryaLYfFYF2J"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyQFgFh6bN-f"
   },
   "outputs": [],
   "source": [
    "# initiate the linear model \n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BZE4wfTbVn1"
   },
   "outputs": [],
   "source": [
    "# scale the features \n",
    "min_mascaler =  preprocessing.MinMaxScaler()\n",
    "scaled_minmax = min_mascaler.fit_transform(X_train)\n",
    "scaled_minmadf = pd.DataFrame(scaled_minmax, columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принцип работы рекурсивного метода исключения признаков следующий:\n",
    "1. Обучает модель на всех признаках.\n",
    "2. Определяет признаки с наименьшим вкладом и удаляет их.\n",
    "3. Повторяет процесс до тех пор, пока не останется нужное количество признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "estimator = SomeEstimator()  # Ваш модельный алгоритм, например, линейная регрессия\n",
    "selector = RFE(estimator, n_features_to_select=5)  # Выбираем 5 признаков\n",
    "selector = selector.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFECV - улучшенная версия RFE, которая использует кросс-валидацию для выбора оптимального количества признаков. Она автоматически определяет, сколько признаков нужно оставить, чтобы добиться лучшего качества модели, учитывая данные с кросс-валидацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1F8JB3VAb3mH",
    "outputId": "65bfd164-b68e-4f8f-ad37-623b08ce9b15"
   },
   "outputs": [],
   "source": [
    "# recursive feature elimination with cross validation, using r-squared as metric \n",
    "rfecv = RFECV(estimator=lm, step=1, cv=5) \n",
    "rfecv.fit(scaled_minmadf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wjWN1N8b6et",
    "outputId": "811403d2-55c6-4107-ac52-c2dadbf787da"
   },
   "outputs": [],
   "source": [
    "# print the optimal number of feature \n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот график иллюстрирует, как качество модели (в данном случае по метрике mean squared error — среднеквадратичная ошибка) меняется в зависимости от количества выбранных признаков при использовании метода RFECV (Recursive Feature Elimination with Cross-Validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "aDQpaal9aBoP",
    "outputId": "2ce93c72-3617-4759-9034-2d75b9169316"
   },
   "outputs": [],
   "source": [
    "# plot number of features VS. cross-validation scores \n",
    "plt.figure(figsize=(6 * 1.618, 6)) \n",
    "plt.xlabel(\"Number of features selected\") \n",
    "plt.ylabel(\"mean-squared-error\") \n",
    "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель на выбранных признаках и нормализованных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1srhlW3cXcR",
    "outputId": "330e5f23-5367-4431-837c-ce75587fd438"
   },
   "outputs": [],
   "source": [
    "# %% fit model с выбранными функциями  \n",
    "#%% fit model with selected features X_train_new = X_train[:,rfecv.support_] \n",
    "X_train_new = X_train.values[:,rfecv.support_]\n",
    "lm2 = LinearRegression() \n",
    "lm2.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOpnVLhVgqV8",
    "outputId": "543b25db-ff6b-42c0-9879-ad5bfd49ece2"
   },
   "outputs": [],
   "source": [
    "predicted = lm2.predict(X_train_new)\n",
    " \n",
    "rmse = np.sqrt(np.mean((predicted-y_train)**2))\n",
    "print(\"Root Mean Squared Error: {0:0.4f}\" .format(rmse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2Gq4UHGVhVI",
    "outputId": "d1ad2792-9ada-4ff1-a9ff-a2531489dafc"
   },
   "outputs": [],
   "source": [
    "# print the R-squared \n",
    "print(\"The R-squared value is: {0:0.4f} \\n\".format(lm2.score(X_train_new, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hK6vrjpZWGUY",
    "outputId": "d44e907b-8f7b-4338-d28d-acb1b68b09f4"
   },
   "outputs": [],
   "source": [
    "feature_cols_selected = list(np.array(feature_names)[rfecv.support_]) \n",
    "# print intercept and coefficients\n",
    "param_df = pd.DataFrame({\"Features\": ['intercept'] + feature_cols_selected , \n",
    "\"Coef\": [lm2.intercept_] + list(lm2.coef_)})\n",
    "\n",
    "cols = param_df.columns.tolist()\n",
    "cols = cols[-1:]+cols[:-1] \n",
    "param_df = param_df[cols] \n",
    "print(param_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Оценим работу модели на тестовых данных</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kEm7EA5Wtmf"
   },
   "outputs": [],
   "source": [
    "# %% проверить производительность по тестовым данным \n",
    "#%% check performance on test data\n",
    "X_test_part = X_test.values[:,rfecv.support_]\n",
    "predicted = lm2.predict(X_test_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ7vgPuTYiZH"
   },
   "outputs": [],
   "source": [
    "mae = np.mean(abs(predicted-y_test))\n",
    "rmse = np.sqrt(np.mean((predicted-y_test)**2))\n",
    "rae = np.mean(abs(predicted-y_test))/np.mean(abs(y_test-np.mean(y_test)))\n",
    "rse = np.mean((predicted-y_test)**2)/np.mean((y_test-np.mean(y_test)))\n",
    "rse = np.mean((predicted-y_test)**2)/np.mean((y_test-np.mean(y_test))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAVgJocjl_82"
   },
   "source": [
    "# Ridge regression and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Ridge Regression (гребневая регрессия)`** — это вид линейной регрессии, который использует L2-регуляризацию, добавляя штраф к сумме квадратов коэффициентов. Это помогает уменьшить переобучение, особенно когда признаки имеют высокую корреляцию или когда количество признаков велико по сравнению с количеством наблюдений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Когда использовать:</b>\n",
    "- Когда есть многоколлинеарность между признаками (высокая корреляция между независимыми переменными).\n",
    "- Когда модель склонна к переобучению из-за большого числа признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- alpha=0.5: Параметр регуляризации, который определяет силу L2-регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGMTDdo6l_LG"
   },
   "outputs": [],
   "source": [
    " from sklearn import linear_model\n",
    "Ridge = linear_model.Ridge(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NzJoGHz2aKN",
    "outputId": "0328b3c1-3718-49ed-d831-942d58584c11"
   },
   "outputs": [],
   "source": [
    "Ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eZaoYCP2rbG",
    "outputId": "687f0255-6564-4ce5-d39f-dd6582f42c04"
   },
   "outputs": [],
   "source": [
    "print(\"The R-squared value is: {0:0.4f} \\n\".format(Ridge.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PjFkJ9827aH",
    "outputId": "8f15e74f-186d-4501-cea2-a833e3ec3c9e"
   },
   "outputs": [],
   "source": [
    "param_df = pd.DataFrame({\"Features\": ['intercept'] + list(feature_names), \n",
    "\"Coef\": [Ridge.intercept_] + list(Ridge.coef_)}) \n",
    "cols = param_df.columns.tolist() \n",
    "cols = cols[-1:]+cols[:-1] \n",
    "param_df = param_df[cols] \n",
    "print(param_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1hvLrF23kkx"
   },
   "outputs": [],
   "source": [
    "predicted_Ridge = Ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Z22Htd036Cz"
   },
   "outputs": [],
   "source": [
    "mae = np.mean(abs(predicted_Ridge-y_test))\n",
    "rmse = np.sqrt(np.mean((predicted_Ridge-y_test)**2))\n",
    "rae = np.mean(abs(predicted_Ridge-y_test))/np.mean(abs(y_test-np.mean(y_test)))\n",
    "rse = np.mean((predicted_Ridge-y_test)**2)/np.mean((y_test-np.mean(y_test))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWpmyfdlUwQN"
   },
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Lasso-регуляризация (Least Absolute Shrinkage and Selection Operator)`** — это метод регуляризации, используемый в линейных моделях, который добавляет L1-регуляризацию. В отличие от Ridge-регуляризации, которая использует L2-регуляризацию, Lasso-регуляризация добавляет штраф к сумме абсолютных значений коэффициентов признаков, а не к их квадратам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Особенности Lasso-регуляризации</b><br>\n",
    "Lasso-регуляризация помогает модели в решении двух основных задач:\n",
    "\n",
    "1. Уменьшение переобучения — как и другие методы регуляризации, она ограничивает величину коэффициентов, что делает модель более устойчивой.\n",
    "2. Отбор признаков — в отличие от Ridge-регуляризации, Lasso может занулять некоторые коэффициенты, полностью исключая соответствующие признаки из модели. Это делает Lasso полезной для отбора признаков, так как модель автоматически оставляет только наиболее значимые признаки, зануляя остальные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Когда использовать Lasso-регуляризацию?</b>\n",
    "- Когда необходимо не только уменьшить переобучение, но и выполнить отбор признаков.\n",
    "- Когда у модели слишком много признаков, и нужно отобрать только те, которые действительно важны для предсказаний.\n",
    "- Когда есть подозрение, что некоторые признаки незначимы или сильно коррелируют с другими признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- alpha=0.1: Параметр регуляризации, который контролирует степень воздействия L1-регуляризации на модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4aVR17n8U5GP",
    "outputId": "ead3ded0-178d-4760-96b7-e6c27bfb61e3"
   },
   "outputs": [],
   "source": [
    "Lasso = linear_model.Lasso(alpha=0.1)\n",
    "Lasso.fit(X_train, y_train)\n",
    "print(\"The R-squared value is: {0:0.4f} \\n\".format(Lasso.score(X_train, y_train)))\n",
    "param_df = pd.DataFrame({\"Features\": ['intercept'] + list(feature_names), \n",
    "\"Coef\": [Lasso.intercept_] + list(Lasso.coef_)}) \n",
    "cols = param_df.columns.tolist() \n",
    "cols = cols[-1:]+cols[:-1] \n",
    "param_df = param_df[cols] \n",
    "print(param_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kcX0mEeWnhe"
   },
   "source": [
    "## ElasticNetCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ElasticNetCV`**— это модель регуляризации, которая объединяет свойства Lasso и Ridge регрессии, используя L1 и L2 регуляризации одновременно. В отличие от обычной ElasticNet, ElasticNetCV выполняет кросс-валидацию для подбора оптимальных значений гиперпараметров регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преимущества и недостатки ElasticNetCV\n",
    "Преимущества:\n",
    "\n",
    "- Автоматический отбор признаков: Зануляет коэффициенты для некоторых признаков, если они менее значимы, как в Lasso.\n",
    "- Гибкость регуляризации: ElasticNet позволяет комбинировать L1 и L2 регуляризацию, адаптируясь к особенностям данных.\n",
    "- Кросс-валидация: ElasticNetCV автоматически подбирает лучшие значения параметров для конкретных данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недостатки:\n",
    "\n",
    "- Чувствительность к гиперпараметрам: Несмотря на то, что ElasticNetCV находит оптимальные значения alpha и l1_ratio, на большом количестве данных и признаков настройка может быть вычислительно затратной.\n",
    "- Подходит только для линейных моделей: Как и Lasso и Ridge, ElasticNet применим только к задачам с линейными зависимостями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv=10: Указывает количество фолдов для кросс-валидации. В данном случае используется 10-кратная кросс-валидация. Это значит, что данные будут разбиты на 10 частей (фолдов), и на каждом фолде модель будет обучаться на 9 частях данных и проверяться на оставшейся части. Среднее значение ошибки по всем 10 фолдам используется для выбора оптимальных значений alpha и l1_ratio.\n",
    "\n",
    "- random_state=0: Устанавливает начальное состояние для генератора случайных чисел, чтобы результат кросс-валидации был воспроизводимым. Это полезно для консистентности результатов при каждом запуске кода, так как случайное разбиение данных будет одинаковым при каждом повторении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8T76mccFXSOP",
    "outputId": "35c38aef-8bad-4610-bd4d-aed63f1d7426"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "ElasticNetCV = ElasticNetCV(cv=10, random_state=0)\n",
    "ElasticNetCV.fit(X_train, y_train)\n",
    "print(\"The R-squared value is: {0:0.4f} \\n\".format(ElasticNetCV.score(X_train, y_train)))\n",
    "param_df = pd.DataFrame({\"Features\": ['intercept'] + list(feature_names), \n",
    "\"Coef\": [ElasticNetCV.intercept_] + list(ElasticNetCV.coef_)}) \n",
    "cols = param_df.columns.tolist() \n",
    "cols = cols[-1:]+cols[:-1] \n",
    "param_df = param_df[cols] \n",
    "print(param_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie9d6so-UvZT"
   },
   "source": [
    "# SGD (стохастический градиентный спуск)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Стохастический градиентный спуск (Stochastic Gradient Descent, SGD)`** — это популярный метод оптимизации, используемый для обучения моделей машинного обучения, особенно в задачах линейной регрессии, логистической регрессии и нейронных сетей. Этот метод является разновидностью градиентного спуска, которая ускоряет процесс обучения, делая обновление параметров модели на основе случайного подмножества данных (батча), а не на всём тренировочном наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преимущества и недостатки SGD\n",
    "Преимущества:\n",
    "- Скорость и эффективность: Поскольку SGD обновляет параметры на основе одного (или небольшого количества) примера, он требует меньше вычислений и быстрее работает на больших наборах данных.\n",
    "- Шум и рандомизация: Шум в оценках градиента может помочь выбрать более удачный путь к оптимуму, позволяя алгоритму избежать локальных минимумов.\n",
    "- Гибкость и масштабируемость: Подходит для огромных наборов данных, так как требует меньшего объёма памяти.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недостатки:\n",
    "- Сходится медленнее и менее стабильно: Из-за использования только одного образца данных на итерацию обновления параметров могут \"скакать\", из-за чего алгоритм сходится медленно и менее стабильно.\n",
    "- Чувствительность к скорости обучения: Выбор подходящего значения для скорости обучения η критичен. Слишком высокое значение приведёт к нестабильности, а слишком низкое замедлит сходимость.\n",
    "- Не всегда достигает глобального минимума: Стохастичность в процессе обновления градиента может не позволить алгоритму достичь истинного минимума функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Варианты стохастического градиентного спуска\n",
    "Существуют улучшенные методы, которые уменьшают недостатки базового SGD:\n",
    "\n",
    "- Mini-Batch Gradient Descent: Обновляет параметры на основе небольших батчей (подмножества данных) вместо одного примера. Это уменьшает шум и делает процесс более стабильным.\n",
    "- Momentum (моментум): Добавляет инерцию, помогая сглаживать и ускорять процесс оптимизации.\n",
    "- AdaGrad, RMSProp и Adam: Это адаптивные методы, которые динамически изменяют скорость обучения для каждого параметра, ускоряя сходимость и улучшая стабильность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixsRD3QtUL7W"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_iter=1000: Максимальное количество итераций.\n",
    "- tol=1e-3: Критерий для остановки, если изменения в потере становятся меньше 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZJXaFGPUuCN",
    "outputId": "99d5ff88-42c7-4afd-d98c-10cb206e075e"
   },
   "outputs": [],
   "source": [
    "SGD = make_pipeline(StandardScaler(),\n",
    "...                     SGDRegressor(max_iter=1000, tol=1e-3))\n",
    "SGD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uX0U0kbCUtxz",
    "outputId": "fc74f2bc-ef77-45f5-f988-478dc375387e"
   },
   "outputs": [],
   "source": [
    "print(\"The R-squared value is: {0:0.4f} \\n\".format(SGD.score(X_train, y_train)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Boston_sklearn_выбор признаков_1.ipynb\"\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
